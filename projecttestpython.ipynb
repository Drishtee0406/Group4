{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_emb = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271927\n"
     ]
    }
   ],
   "source": [
    "#Read file and inspect it\n",
    "with open ('Ghostship.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#Lenght\n",
    "lenght_text = len(text)\n",
    "print(lenght_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 1: Dataset Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'*,-.0679:;?ABCDEFGHIJKLMNOPQRSTUVWY`abcdefghijklmnopqrstuvwxyzèé—\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Unique characters in Ghostship\n",
    "characters = sorted(list(set(text))) #chars\n",
    "num_characters = len(characters) #vocab_size\n",
    "print(''.join(characters))\n",
    "print(num_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode and decode\n",
    "encode0 = {ch:i for i,ch in enumerate(characters)} #stoi\n",
    "decode0 = {i:ch for i,ch in enumerate(characters)} #itos\n",
    "encode = lambda s: [encode0[c] for c in s]\n",
    "decode = lambda l: ''.join([decode0[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([271927]) torch.int64\n",
      "tensor([21, 41, 49, 58, 46, 49, 45, 52, 44,  1, 49, 59,  1, 41,  1, 52, 49, 60,\n",
      "        60, 52, 45,  1, 62, 49, 52, 52, 41, 47, 45,  1, 52, 65, 49, 54, 47,  1,\n",
      "        54, 45, 41, 58,  1, 60, 48, 45,  1, 31, 55, 58, 60, 59, 53, 55, 61, 60,\n",
      "        48,  1, 33, 55, 41, 44,  1, 41, 42, 55, 61, 60,  1, 48, 41, 52, 46,  7,\n",
      "        63, 41, 65,  1, 42, 45, 60, 63, 45, 45, 54,  1, 27, 55, 54, 44, 55, 54,\n",
      "         1, 41, 54, 44,  1, 60, 48, 45,  1, 59, 45, 41,  8,  1, 34, 60, 58, 41,\n",
      "        54, 47, 45, 58, 59,  1, 63, 48, 55,  1, 46, 49, 54, 44,  1, 49, 60,  1,\n",
      "        42, 65,  1, 41, 43, 43, 49, 44, 45, 54, 60,  1, 54, 55, 63,  1, 41, 54,\n",
      "        44,  1, 60, 48, 45, 54,  6,  1, 43, 41, 52, 52,  1, 49, 60,  1, 41,  1,\n",
      "        56, 58, 45, 60, 60, 65,  6,  1, 55, 52, 44,  7, 46, 41, 59, 48, 49, 55,\n",
      "        54, 45, 44,  1, 56, 52, 41, 43, 45, 14,  1, 63, 45,  1, 63, 48, 55,  1,\n",
      "        52, 49, 62, 45,  1, 49, 54,  1, 49, 60,  1, 41, 54, 44,  1, 43, 41, 52,\n",
      "        52,  1, 49, 60,  1, 48, 55, 53, 45,  1, 44, 55, 54,  4, 60,  1, 46, 49,\n",
      "        54, 44,  1, 41, 54, 65, 60, 48, 49, 54, 47,  1, 62, 45, 58, 65,  1, 56,\n",
      "        58, 45, 60, 60, 65,  1, 41, 42, 55, 61, 60,  1, 49, 60,  6,  1, 42, 61,\n",
      "        60,  1, 63, 45,  1, 59, 48, 55, 61, 52, 44,  1, 42, 45,  1, 59, 55, 58,\n",
      "        58, 65,  1, 60, 55,  1, 52, 49, 62, 45,  1, 41, 54, 65, 63, 48, 45, 58,\n",
      "        45,  1, 45, 52, 59, 45,  8,  1, 30, 61, 58,  1, 53, 49, 54, 44, 59,  1,\n",
      "        48, 41, 62, 45,  1, 60, 41, 51, 45, 54,  1, 60, 48, 45,  1, 59, 48, 41,\n",
      "        56, 45,  1, 55, 46,  1, 60, 48, 45,  1, 49, 54, 54,  1, 41, 54, 44,  1,\n",
      "        60, 48, 45,  1, 43, 48, 61, 58, 43, 48,  1, 41, 54, 44,  1, 60, 48, 45,\n",
      "         1, 47, 58, 45, 45, 54,  6,  1, 24,  1, 59, 61, 56, 56, 55, 59, 45,  8,\n",
      "         1, 16, 60,  1, 41, 52, 52,  1, 45, 62, 45, 54, 60, 59,  1, 63, 45,  1,\n",
      "        54, 45, 62, 45, 58,  1, 46, 45, 45, 52,  1, 43, 55, 53, 46, 55, 58, 60,\n",
      "        41, 42, 52, 45,  1, 55, 61, 60,  1, 55, 46,  1, 21, 41, 49, 58, 46, 49,\n",
      "        45, 52, 44,  8,  0,  0, 30, 46,  1, 43, 55, 61, 58, 59, 45,  1, 60, 48,\n",
      "        45,  1, 18, 55, 43, 51, 54, 45, 65, 59,  6,  1, 63, 49, 60, 48,  1, 60,\n",
      "        48, 45, 49, 58,  1, 62, 41, 59, 60, 65,  1, 48, 55, 61, 59, 45, 59,  1,\n",
      "        41, 54, 44,  1, 54, 55, 49, 59, 45,  7, 58, 49, 44, 44, 45, 54,  1, 59,\n",
      "        60, 58, 45, 45, 60, 59,  6,  1, 43, 41, 54,  1, 43, 41, 52, 52,  1, 61,\n",
      "        59,  1, 58, 61, 59, 60, 49, 43, 59,  1, 49, 46,  1, 60, 48, 45, 65,  1,\n",
      "        43, 48, 55, 55, 59, 45,  6,  1, 42, 61, 60,  1, 46, 55, 58,  1, 41, 52,\n",
      "        52,  1, 60, 48, 41, 60,  1, 21, 41, 49, 58, 46, 49, 45, 52, 44,  1, 49,\n",
      "        59,  1, 41,  1, 42, 45, 60, 60, 45, 58,  1, 56, 52, 41, 43, 45,  1, 60,\n",
      "        55,  1, 52, 49, 62, 45,  1, 49, 54,  1, 60, 48, 41, 54,  1, 27, 55, 54,\n",
      "        44, 55, 54,  8,  1, 19, 55, 43, 60, 55, 58,  1, 59, 41, 65, 59,  1, 60,\n",
      "        48, 41, 60,  1, 63, 48, 45, 54,  1, 48, 45,  1, 47, 55, 45, 59,  1, 60,\n",
      "        55,  1, 27, 55, 54, 44, 55, 54,  1, 48, 49, 59,  1, 53, 49, 54, 44,  1,\n",
      "        49, 59,  1, 42, 58, 61, 49, 59, 45, 44,  1, 63, 49, 60, 48,  1, 60, 48,\n",
      "        45,  1, 63, 45, 49, 47, 48, 60,  1, 55, 46,  1, 60, 48, 45,  1, 48, 55,\n",
      "        61, 59, 45, 59,  6,  1, 41, 54, 44,  1, 48, 45,  1, 63, 41, 59,  1, 41,\n",
      "         1, 18, 55, 43, 51, 54, 45, 65,  1, 42, 55, 58, 54,  8,  1, 23, 45,  1,\n",
      "        48, 41, 44,  1, 60, 55,  1, 52, 49, 62, 45,  1, 60, 48, 45, 58, 45,  1,\n",
      "        48, 49, 53, 59, 45, 52, 46,  1, 63, 48, 45, 54,  1, 48, 45,  1, 63, 41,\n",
      "        59,  1, 41,  1, 52, 49, 60, 60, 52, 45,  1, 43, 48, 41, 56,  6,  1, 42,\n",
      "        61, 60,  1, 48, 45,  1, 51, 54, 55, 63, 59,  1, 42, 45, 60, 60, 45, 58,\n",
      "         1, 54, 55, 63,  8,  1, 39, 55, 61,  1, 47, 45, 54, 60, 52, 45, 53, 45,\n",
      "        54,  1, 53, 41, 65,  1, 52, 41, 61, 47, 48, 69, 56, 45, 58, 48, 41, 56,\n",
      "        59,  1, 59, 55, 53, 45,  1, 55, 46,  1, 65, 55, 61,  1, 43, 55, 53, 45,\n",
      "         1, 46, 58, 55, 53,  1, 27, 55, 54, 44, 55, 54,  1, 63, 41, 65, 69, 42,\n",
      "        61, 60,  1, 49, 60,  1, 59, 45, 45, 53, 59,  1, 60, 55,  1, 53, 45,  1,\n",
      "        60, 48, 41, 60,  1, 41,  1, 63, 49, 60, 54, 45, 59, 59,  1, 52, 49, 51,\n",
      "        45,  1, 60, 48, 41, 60,  1, 49, 59,  1, 63, 55, 58, 60, 48,  1, 41,  1,\n",
      "        47, 41, 52, 52, 55, 54,  1, 55, 46,  1, 41, 58, 47, 61, 53, 45, 54, 60,\n",
      "        59,  8,  0,  0, 19, 61, 52, 52, 15,  1, 38, 45, 52, 52,  6,  1, 65, 55,\n",
      "        61,  1, 53, 49, 47, 48, 60,  1, 46, 49])\n"
     ]
    }
   ],
   "source": [
    "#Encode dataset and store it into a torch\n",
    "dataset = torch.tensor(encode(text), dtype=torch.long)#\n",
    "print(dataset.shape, dataset.dtype)\n",
    "print(dataset[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation sets\n",
    "n = int(0.9*len(dataset))\n",
    "training_data = dataset[:n]#\n",
    "validation_data = dataset[n:]#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 #Maximum number of characters in a group\n",
    "x = training_data[:block_size]#\n",
    "y = training_data[1:block_size + 1]#\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    dataset = training_data if split == 'train' else validation_data#data, #train_data\n",
    "    ix = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([dataset[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "torch.Size([4, 8])\n",
      "tensor([[49, 60,  1, 59, 48, 55, 61, 52],\n",
      "        [52, 52, 61, 59, 49, 55, 54, 59],\n",
      "        [65,  8,  1,  3, 24,  1, 42, 45],\n",
      "        [ 1, 56, 58, 45, 59, 45, 54, 60]])\n",
      "target:\n",
      "torch.Size([4, 8])\n",
      "tensor([[60,  1, 59, 48, 55, 61, 52, 44],\n",
      "        [52, 61, 59, 49, 55, 54, 59,  1],\n",
      "        [ 8,  1,  3, 24,  1, 42, 45, 60],\n",
      "        [56, 58, 45, 59, 45, 54, 60, 52]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('input:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('target:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 2: Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 70])\n",
      "tensor(4.6413, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocabulary_size):#vocab_size\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            #Calculate quality of predictions (logits versus expected targets)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    #generate function for the model\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(num_characters)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Train the model on the selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch optimization object -> CHANGE and use estimate_loss()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb) #evaluating the loss\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Track performance metrics such as loss during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Print out average training loss and validation loss at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3646795749664307\n"
     ]
    }
   ],
   "source": [
    "print (loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Print out generated tokens/text to preview the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"TEd we whinket nds a th co alime re theshurd acouthke Buche woly, thin h he Heeroos sted wabo. r is I m, n thur be, ke issl, Ye tr' w in I sa erlla ilisablldour ve m tf wist in'sey, y g.\n",
      "\"Vary gertheshad the brt th ssttsu ve d sthe titheve mene s d Ont mout t thid ce f pe his de l Thay t to Hemeve\n"
     ]
    }
   ],
   "source": [
    "Milestone2_output = decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=300)[0].tolist())\n",
    "print(Milestone2_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Save generated text of 300 tokens to a file called milestone2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been saved to milestone2.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"milestone2.txt\", \"w\") as file:\n",
    "    file.write(Milestone2_output)\n",
    "\n",
    "print(\"Text has been saved to milestone2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 3: Self-attention & Softmax Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Update the provided model to include Self-attention Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
